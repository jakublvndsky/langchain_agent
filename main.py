import os
import requests
import nest_asyncio
import asyncio
import bs4
from typing import Literal
from dotenv import load_dotenv
from pinecone import Pinecone, ServerlessSpec
from langchain.messages import SystemMessage, HumanMessage
from langchain_mcp_adapters.client import MultiServerMCPClient
from langchain.tools import tool
from langchain.agents import create_agent
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_ollama import ChatOllama
from langgraph.checkpoint.memory import InMemorySaver
from langchain_pinecone import PineconeVectorStore
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import WebBaseLoader


load_dotenv()

nest_asyncio.apply()


async def load_mcp():
    mcp_client = MultiServerMCPClient(
        {
            "time": {
                "transport": "stdio",
                "command": "npx",
                "args": ["-y", "@theo.foobar/mcp-time"],
            }
        },
    )

    mcp_tools = await mcp_client.get_tools()
    print(f"Loaded {len(mcp_tools)} MCP tools: {[t.name for t in mcp_tools]}")
    return mcp_tools


OPENAI_API_KEY = os.environ["OPENAI_API_KEY"]
PINECONE_API_KEY = os.environ["PINECONE_API_KEY"]


class LLMError(Exception):
    pass


embeddings = OpenAIEmbeddings(model="text-embedding-3-small")

pc = Pinecone(PINECONE_API_KEY)

indexes = pc.list_indexes()

try:
    index = pc.Index("langchain-agent")
    print("Znalazem indeks")
except Exception as e:
    print(f"Nie udao si poczy do indeksu w bazie wektorowej: {e}")
    print("==== Tworz nowy indeks w bazie wektorowej ====")
    index = pc.create_index(
        name="langchain-agent",
        dimension=1536,
        spec=ServerlessSpec(cloud="aws", region="us-east-1"),
        metric="cosine",
    )
    print("Utworzyem indeks")


vector_store = PineconeVectorStore(index=index, embedding=embeddings)

bs4_strainer = bs4.SoupStrainer(class_=("post-title", "post-header", "post-content"))
loader = WebBaseLoader(
    web_paths=("https://lilianweng.github.io/posts/2023-06-23-agent/",),
    bs_kwargs={"parse_only": bs4_strainer},
)
docs = loader.load()

assert len(docs) == 1

text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=1000, chunk_overlap=200, add_start_index=True
)


all_splits = text_splitter.split_documents(docs)

document_ids = vector_store.add_documents(documents=all_splits)


@tool
def retrive_context(query: str):
    """Przetwarza informacje z bazy wektorowej w celu udzielenia dokadniejszej odpowiedzi"""
    retrived_docs = vector_store.similarity_search(query=query, k=3)
    serialized = "\n\n".join(
        (f"Source: {doc.metadata}\nContent: {doc.page_content}")
        for doc in retrived_docs
    )
    return serialized, retrived_docs


@tool(
    description=(
        "Bardzo prosty kalkulator przyjmujacy dwie liczby i wykonujacy na nich akcje zgodnie z podanym znakiem"
    ),
    parse_docstring=True,
)
def liczenie(
    a: int | float, b: int | float, znak: Literal["+", "-", "*", "/"]
) -> float:
    """Pozwala obliczy dwie liczby

    Args:
        a: pierwsza liczba w dziaaniu
        b: druga liczba w dziaaniu
        znak: jest to argument, kt贸ry przyjmuje:
            "-" czyli dodawanie a - b
            "+" czyli odejmowanie a + b
            "*" czyli mno偶enie a * b
            "/" czyli dzielenie a / b
    """
    print("Zaczynam liczenie М")
    if znak == "+":
        return a + b
    elif znak == "-":
        return a - b
    elif znak == "*":
        return a * b
    elif znak == "/":
        if b == 0:
            raise ZeroDivisionError("Nie mo偶na dzieli przez zero")
        return a / b
    else:
        raise ValueError("Nie waciwy znak zosta podany")


@tool(
    "kantor",
    description=("Sluzy do wyszukiwania kursu waluty po jej kodzie zgodnie z ISO 4217"),
    parse_docstring=True,
)
def sprawdz_kurs_waluty(kod_waluty: str) -> dict:
    """Sprawdza kursy walut z polskiej na waluty obce

    Args:
        kod_waluty: jest to kod waluty, kt贸ry jest zgodny z oznaczeniem ISO 4217
    """

    r = requests.get(
        f"http://api.nbp.pl/api/exchangerates/rates/A/{kod_waluty}/?format=json"
    )
    if r.status_code == 200:
        response = r.json()
        return response
    else:
        raise Exception(f"Jest bdny status usugi, a dokadnie {r.status_code}")


provider = ChatOpenAI(
    model="gpt-5-mini", temperature=0.4, max_retries=2, api_key=OPENAI_API_KEY
)

ollama_provider = ChatOllama(model="llama3.2:3b", temperature=0.4)

system_msg = SystemMessage(
    """Jeste moim osobistym pomocnikiem o imieniu Orion, a ja mam na imi Kuba. 
        Obecnie masz bardzo prostego toola podczonego, kt贸ry potrafi liczy proste rzeczy dodawanie, odejmowanie, mno偶enie i dzielenie.
        Drugi tool to wyszukiwanie urednionego kursu walut wedle kursu NBP - nalezy podawa kod waluty zgodny z oznaczeniem ISO 4217
        Trzeci tool to dostp do bazy wektorowej, kt贸ra ma za zadanie pogbi Twoj wiedz na zadawane pytanie odnonie tematyki Autonomicznych Agent贸w zasilanych LLM-ami - u偶ywaj go aby udziela lepszych odpowiedzi u偶ytkownikowi
        Czwarty tool to serwer mcp, kt贸ry jest od sprawdzania czasu
    """
)
human_msg = HumanMessage(
    "Sprawd藕 kurs waluty dolara amerykaskiego, a nastpnie oblicz ile by go byo za 100 zotych oraz sprawd藕 godzin w Nowym Jorku"
)

config = {"configurable": {"thread_id": "1"}}
checkpointer = InMemorySaver()


async def build_agent():
    mcp_tools = await load_mcp()
    agent = create_agent(
        model=provider,
        tools=[liczenie, sprawdz_kurs_waluty, retrive_context, *mcp_tools],
        system_prompt=system_msg,
        checkpointer=checkpointer,
    )

    return agent


steps = []


async def chat():
    agent = await build_agent()
    while True:
        try:
            text = await asyncio.to_thread(input, "Cze, w czym Ci dzisiaj pom贸c?\n")
        except (EOFError, KeyboardInterrupt):
            break

        text = text.strip()
        if not text:
            continue
        if text.lower() in {"exit", "quit", "q"}:
            break

        prompt = HumanMessage(text)
        async for response in agent.astream(
            {"messages": [prompt]}, config=config, stream_mode="values"
        ):
            response["messages"][-1].pretty_print()
            steps.append(response)


if __name__ == "__main__":
    asyncio.run(chat())
